{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Курсовая TestGAN",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15VMUIgtSMxi_bJld9LGs7g5AQWR_FxEN",
      "authorship_tag": "ABX9TyMJnfuB66N1kDVWQ+TZkNsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fayzak/CourseWorkGAN/blob/main/%D0%9A%D1%83%D1%80%D1%81%D0%BE%D0%B2%D0%B0%D1%8F_TestGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpPfcxMGBMX6"
      },
      "source": [
        "**Импорт библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suWF7ctIBTFr"
      },
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        " \n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, Conv2DTranspose, concatenate, MaxPooling2D, Conv2D, BatchNormalization, Dropout, UpSampling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers import LeakyReLU, AveragePooling2D, Activation\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        " \n",
        "import os\n",
        "from google.colab import drive\n",
        "import time\n",
        "import pickle\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOyQNA2c2itb"
      },
      "source": [
        "import os, datetime\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import Input, Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
        "    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\n",
        "from keras.layers import add\n",
        "from keras.optimizers import Adam\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaHKrg-d7eWg"
      },
      "source": [
        "# Работа с данными"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ3ZXqxWJy4b"
      },
      "source": [
        "# 1) Импортирование данных и изменение размера\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "main_dir = 'drive/My Drive/Diplom/Base/TestBasePokemons'\n",
        "\n",
        "src = f'{main_dir}/data'\n",
        "dst = f'{main_dir}/resizedData'\n",
        "\n",
        "# os.mkdir(dst)\n",
        "\n",
        "for each in os.listdir(src):\n",
        "  img = cv2.imread(os.path.join(src, each))\n",
        "  img = cv2.resize(img, (64, 64))\n",
        "  cv2.imwrite(os.path.join(dst,each), img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNeHiw0fS2hA"
      },
      "source": [
        "# 2) Изменение цветности заднего фона изображений\n",
        "main_dir = 'drive/My Drive/Diplom/Base/TestBasePokemons'\n",
        "src = f'{main_dir}/resizedData'\n",
        "dst = f'{main_dir}/resized_black'\n",
        "\n",
        "for each in os.listdir(src):\n",
        "  png = Image.open(os.path.join(src, each))\n",
        "  if png.mode == 'RGBA':\n",
        "    png.load()\n",
        "    bg = Image.new(\"RGB\", png.size, (0, 0, 0))\n",
        "    bg.paste(png, mask=png.split()[3])\n",
        "    bg.save(os.path.join(dst, each.split('.')[0] + '.jpg'), 'JPEG')\n",
        "  else:\n",
        "    png.convert('RGB')\n",
        "    png.save(os.path.join(dst, each.split('.')[0] + '.jpg'), 'JPEG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DDfSZ5JS8qF"
      },
      "source": [
        "# 3) Cоздание выборки\n",
        " \n",
        "def work_on_data():\n",
        "  main_dir = 'drive/My Drive/Diplom/Base/TestBasePokemons'\n",
        "  pokemon_dir = f'{main_dir}/resized_black/'\n",
        " \n",
        "  xTrain = []\n",
        " \n",
        "  arr = os.listdir(pokemon_dir)\n",
        " \n",
        "  for each in arr:\n",
        "    xpath = os.path.join(pokemon_dir, each)\n",
        "    img = np.asarray(image.load_img(xpath))\n",
        "    xTrain.append(np.asarray(img))\n",
        " \n",
        "  xTrain = np.array(xTrain)\n",
        " \n",
        "  return xTrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWvQD-JB3Diy"
      },
      "source": [
        "xTrain = work_on_data()\n",
        "print(xTrain[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t4-8GOF1oGB"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Diplom/Base/directory.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VgyQ7I_8uwA"
      },
      "source": [
        "### Функции для загрузки датасета ###\n",
        "\n",
        "def load_class_ids(class_info_file_path):\n",
        "  \"\"\"\n",
        "  Грузим id класса с файла class_info.pickle\n",
        "  \"\"\"\n",
        "  with open(class_info_file_path, 'rb') as f:\n",
        "    class_ids = pickle.load(f, encoding='latin1')\n",
        "  return class_ids\n",
        "\n",
        "\n",
        "def load_embeddings(embeddings_file_path):\n",
        "  \"\"\"\n",
        "  Загружаем эмбединги для текста\n",
        "  \"\"\"\n",
        "  with open(embeddings_file_path, 'rb') as f:\n",
        "    embeddings = pickle.load(f, encoding='latin1')\n",
        "    embeddings = np.array(embeddings)\n",
        "    print('embeddings: ', embeddings.shape)\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "def load_filenames(filenames_file_path):\n",
        "  \"\"\"\n",
        "  Грузим filenames.pickle и возвращаем все имена файлов\n",
        "  \"\"\"\n",
        "  with open(filenames_file_path, 'rb') as f:\n",
        "    filenames = pickle.load(f, encoding='latin1')\n",
        "  return filenames\n",
        "\n",
        "\n",
        "def load_bounding_boxes(dataset_dir):\n",
        "  \"\"\"\n",
        "  Грузим bounding boxes и возвращаем словарь с именем файла и соответствующем ему bouding box\n",
        "  \"\"\"\n",
        "\n",
        "  # Папки\n",
        "  bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
        "  file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
        "\n",
        "  # Прочитаем bounding_boxes.txt и images.txt\n",
        "  df_bounding_boxes = pd.read_csv(bounding_boxes_path, delim_whitespace=True, header=None).astype(int)\n",
        "  df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
        "\n",
        "  # Создаем список имен файлов\n",
        "  file_names = df_file_names[1].tolist()\n",
        "\n",
        "  # Создаем словарь с именами файлов и bounding boxes\n",
        "  filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
        "\n",
        "  # Определяем bounding box к своему изображению\n",
        "  for i in range(0, len(file_names)):\n",
        "    # Получаем bounding box\n",
        "    bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
        "    key = file_names[i][:-4]\n",
        "    filename_boundingbox_dict[key] = bounding_box\n",
        "\n",
        "  return filename_boundingbox_dict\n",
        "\n",
        "\n",
        "def get_img(img_path, bbox, image_size):\n",
        "  \"\"\"\n",
        "  Загружаем и изменяем размеры изображений\n",
        "  \"\"\"\n",
        "  img = Image.open(img_path).convert('RGB')\n",
        "  width, height = img.size \n",
        "  if bbox is not None:\n",
        "    R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "    center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "    center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "    y1 = np.maximum(0, center_y - R)\n",
        "    y2 = np.minimum(height, center_y + R)\n",
        "    x1 = np.maximum(0, center_x - R)\n",
        "    x2 = np.minimum(width, center_x + R)\n",
        "    img = img.crop([x1, y1, x2, y2])\n",
        "  img = img.resize(image_size, PIL.Image.BILINEAR)\n",
        "  return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
        "  \"\"\"\n",
        "  Полность загружаем датасет, используя предыдущие функции\n",
        "  \"\"\"\n",
        "  filenames = load_filenames(filenames_file_path)\n",
        "  class_ids = load_class_ids(class_info_file_path)\n",
        "  bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
        "  all_embeddings = load_embeddings(embeddings_file_path)\n",
        "\n",
        "  X, y, embeddings = [], [], []\n",
        "\n",
        "  print(\"Embeddings shape:\", all_embeddings.shape)\n",
        "\n",
        "  for index, filename in enumerate(filenames):\n",
        "    bounding_box = bounding_boxes[filename]\n",
        "\n",
        "    try:\n",
        "      # Грузим изображения\n",
        "      img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
        "      img = get_img(img_name, bounding_box, image_size)\n",
        "\n",
        "      all_embeddings1 = all_embeddings[index, :, :]\n",
        "\n",
        "      embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
        "      embedding = all_embeddings1[embedding_ix, :]\n",
        "\n",
        "      X.append(np.array(img))\n",
        "      y.append(class_ids[index])\n",
        "      embeddings.append(embedding)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "  embeddings = np.array(embeddings)\n",
        "  return X, y, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7TH5RgDkwBW"
      },
      "source": [
        "### Создание последовательности обучения, определение гиперпараметров и обучение Первой Стадии StackGAN ### \n",
        "\n",
        "# Определяем параметры\n",
        "\n",
        "data_dir = '/content/directory/birds'\n",
        "train_dir = data_dir + '/train'\n",
        "test_dir = data_dir + '/test'\n",
        "# image_size = 64\n",
        "# batch_size = 64\n",
        "# z_dim = 100\n",
        "# stage1_generator_lr = 2e-4\n",
        "# stage1_discriminator_lr = 2e-4\n",
        "# stage1_lr_decay_step = 600\n",
        "# epochs = 1000\n",
        "# condition_dim = 128\n",
        "\n",
        "embeddings_file_path_train = train_dir + '/char-CNN-RNN-embeddings.pickle'\n",
        "embeddings_file_path_test = test_dir + '/char-CNN-RNN-embeddings.pickle'\n",
        "\n",
        "filenames_file_path_train = train_dir + '/filenames.pickle'\n",
        "filenames_file_path_test = test_dir + '/filenames.pickle'\n",
        "\n",
        "class_info_file_path_train = train_dir + '/class_info.pickle'\n",
        "class_info_file_path_test = test_dir + '/class_info.pickle'\n",
        "\n",
        "cub_dataset_dir = data_dir + '/CUB_200_2011'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzIXYH8z16OS"
      },
      "source": [
        "X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
        "                                                  class_info_file_path=class_info_file_path_train,\n",
        "                                                  cub_dataset_dir=cub_dataset_dir,\n",
        "                                                  embeddings_file_path=embeddings_file_path_train,\n",
        "                                                  image_size=(64, 64))\n",
        "\n",
        "X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
        "                                                  class_info_file_path=class_info_file_path_test,\n",
        "                                                  cub_dataset_dir=cub_dataset_dir,\n",
        "                                                  embeddings_file_path=embeddings_file_path_test,\n",
        "                                                  image_size=(64, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0d_lw_R7hIb"
      },
      "source": [
        "# Нейросеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-05BHc0o7j5X"
      },
      "source": [
        "# Функция генератора\n",
        "def build_generator(img_shape):\n",
        "  channels = img_shape[2]\n",
        "  m_height, m_width = int(img_shape[0]/4), int(img_shape[1]/4)\n",
        " \n",
        "  generator = Sequential(name='generator')\n",
        " \n",
        "  generator.add(Dense(m_height * m_width * 256, input_shape=(latent_dim, )))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU())\n",
        "  generator.add(Reshape((m_height, m_width, 256)))\n",
        " \n",
        "  generator.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "  generator.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "  generator.add(Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
        " \n",
        "  generator.summary()\n",
        " \n",
        "  noise = Input(shape=(latent_dim,))\n",
        "  img = generator(noise)\n",
        " \n",
        "  return Model(noise, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSbpzriJDH1l"
      },
      "source": [
        "# Функция дискриминатора\n",
        "def build_discriminator(img_shape):\n",
        " \n",
        "  discriminator = Sequential(name='discriminator')\n",
        " \n",
        "  discriminator.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=img_shape))\n",
        "  discriminator.add(LeakyReLU())\n",
        "  discriminator.add(Dropout(0.3))\n",
        " \n",
        "  discriminator.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "  discriminator.add(LeakyReLU())\n",
        "  discriminator.add(Dropout(0.3))\n",
        " \n",
        "  discriminator.add(Flatten())\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "  discriminator.summary()\n",
        " \n",
        "  img = Input(shape=img_shape)\n",
        "  validity = discriminator(img)\n",
        " \n",
        "  return Model(img, validity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQujgwUwrJVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4938ad-359c-408d-9268-e38a15bf03e5"
      },
      "source": [
        "# Начальная подготовка данных и их подача в функции сети\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 100\n",
        " \n",
        "optimizer = Adam(0.0002, 0.5)\n",
        " \n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        " \n",
        "generator = build_generator(img_shape)\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        " \n",
        "z = Input(shape=(100,))\n",
        "img = generator(z)\n",
        " \n",
        "discriminator.trainable = False\n",
        " \n",
        "valid = discriminator(img)\n",
        " \n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 32769     \n",
            "=================================================================\n",
            "Total params: 108,417\n",
            "Trainable params: 108,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 65536)             6619136   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 65536)             262144    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       819328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 64)        204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 3)         4803      \n",
            "=================================================================\n",
            "Total params: 7,910,275\n",
            "Trainable params: 7,779,203\n",
            "Non-trainable params: 131,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zePoaY2ZXjU"
      },
      "source": [
        "def save_imgs(epoch):\n",
        "    main_dir = 'drive/My Drive/Diplom/Base/TestBasePokemons'\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        " \n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        " \n",
        "    fig, axs = plt.subplots(r, c, figsize=(14,10))\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(f\"{main_dir}/pokemons_gan/pokemons_%d.png\" % epoch)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BemqGXSSYTGg"
      },
      "source": [
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "  Xtrain = X_train\n",
        "  print('База успешно загружена')\n",
        " \n",
        "  # Xtrain = (Xtrain.astype(np.float32) - 127.5) / 127.5\n",
        "  # X_train = np.expand_dims(X_train, axis=3)\n",
        " \n",
        "  half_batch = int(batch_size / 2)\n",
        " \n",
        "  d_loss_list = []\n",
        "  g_loss_list = []\n",
        "  d_acc_list = []\n",
        " \n",
        "  for epoch in range(epochs):\n",
        " \n",
        "    # Train Discriminator\n",
        " \n",
        "    idx = np.random.randint(0, Xtrain.shape[0], half_batch)\n",
        "    imgs = Xtrain[idx]\n",
        " \n",
        "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
        " \n",
        "    gen_imgs = generator.predict(noise)\n",
        " \n",
        "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        " \n",
        "    # Train Generator\n",
        " \n",
        "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
        " \n",
        "    valid_y = np.array([1] * batch_size)\n",
        " \n",
        "    g_loss = combined.train_on_batch(noise, valid_y)\n",
        " \n",
        "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        " \n",
        "    d_loss_list.append(d_loss[0])\n",
        "    g_loss_list.append(g_loss)\n",
        "    d_acc_list.append(100*d_loss[1])\n",
        " \n",
        "    if epoch % save_interval == 0:\n",
        "      save_imgs(epoch)\n",
        " \n",
        "  plt.figure(figsize=(14,7))\n",
        "  plt.plot(d_loss_list, label=\"Ошибка дискриминатора\")\n",
        "  plt.plot(g_loss_list, label=\"Ошибка генератора\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.plot(d_acc_list, label=\"Точность распознавания дискриминатора\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4naHQQO2ZsDh"
      },
      "source": [
        "for i in range(5): \n",
        "  train(epochs=10000, batch_size=32, save_interval=1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}